{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Game\n"
      ],
      "metadata": {
        "id": "3T45rB3yCdVG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pRniLxlrCbAc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from numpy.random import randint\n",
        "\n",
        "\n",
        "class SnakeGame:\n",
        "    \"Implements the snake game core\"\n",
        "\n",
        "    def __init__(\n",
        "        self, width, height, food_amount=1, border=0, grass_growth=0, max_grass=0\n",
        "    ):\n",
        "        \"Initialize board\"\n",
        "        self.width = width\n",
        "        self.height = height\n",
        "        self.board = np.zeros((height, width, 3), dtype=np.float32)\n",
        "        self.food_amount = food_amount\n",
        "        self.border = border\n",
        "        self.grass_growth = grass_growth\n",
        "        self.grass = np.zeros((height, width)) + max_grass\n",
        "        self.max_grass = max_grass\n",
        "        self.reset()\n",
        "\n",
        "    def create_apples(self):\n",
        "        \"create a new apple away from the snake\"\n",
        "        while len(self.apples) < self.food_amount:\n",
        "            apple = (randint(0, self.height - 1), randint(0, self.width - 1))\n",
        "            while apple in self.snake:\n",
        "                apple = (randint(0, self.height - 1), randint(0, self.width - 1))\n",
        "            self.apples.append(apple)\n",
        "\n",
        "    def create_snake(self):\n",
        "        \"create a snake, size 3, at random position and orientation\"\n",
        "        x = randint(5, self.width - 5)  # not t0o close to border\n",
        "        y = randint(5, self.height - 5)\n",
        "        self.direction = randint(0, 4)\n",
        "        self.snake = []\n",
        "        for i in range(5):\n",
        "            if self.direction == 0:\n",
        "                y = y + 1\n",
        "            elif self.direction == 1:\n",
        "                x = x - 1\n",
        "            elif self.direction == 2:\n",
        "                y = y - 1\n",
        "            elif self.direction == 3:\n",
        "                x = x + 1\n",
        "            self.snake.append((y, x))\n",
        "\n",
        "    def grow_snake(self, d):\n",
        "        \"add one position to snake head (0=up, 1=right, 2=down, 3=left)\"\n",
        "        y, x = self.snake[0]\n",
        "        if d == 0:\n",
        "            y = y - 1\n",
        "        elif d == 1:\n",
        "            x = x + 1\n",
        "        elif d == 2:\n",
        "            y = y + 1\n",
        "        else:\n",
        "            x = x - 1\n",
        "        self.snake.insert(0, (y, x))\n",
        "\n",
        "    def check_collisions(self):\n",
        "        \"check if game is over by colliding with edge or itself\"\n",
        "        # just need to check snake's head\n",
        "        x, y = self.snake[0]\n",
        "        if (\n",
        "            x == -1\n",
        "            or x == self.height\n",
        "            or y == -1\n",
        "            or y == self.width\n",
        "            or (x, y) in self.snake[1:]\n",
        "        ):\n",
        "            self.done = True\n",
        "\n",
        "    def step(self, action):\n",
        "        \"\"\"\n",
        "        move snake/game one step\n",
        "        action can be -1 (turn left), 0 (continue), 1 (turn rignt)\n",
        "        \"\"\"\n",
        "        direction = int(action)\n",
        "        assert -1 <= direction <= 1\n",
        "        self.direction += direction\n",
        "        if self.direction < 0:\n",
        "            self.direction = 3\n",
        "        elif self.direction > 3:\n",
        "            self.direction = 0\n",
        "        self.grow_snake(self.direction)  # two steps: grow+remove last\n",
        "        if self.snake[0] in self.apples:\n",
        "            self.apples.remove(self.snake[0])\n",
        "            reward = 1\n",
        "            self.create_apples()  # new apple\n",
        "        else:\n",
        "            self.snake.pop()\n",
        "            self.check_collisions()\n",
        "            if self.done:\n",
        "                reward = -1\n",
        "            else:\n",
        "                reward = 0\n",
        "        if reward >= 0:\n",
        "            x, y = self.snake[0]\n",
        "            reward += self.grass[x, y]\n",
        "            self.grass[x, y] = 0\n",
        "            self.score += reward\n",
        "            self.grass += self.grass_growth\n",
        "            self.grass[self.grass > self.max_grass] = self.max_grass\n",
        "\n",
        "        return self.board_state(), reward, self.done, {\"score\": self.score}\n",
        "\n",
        "    def get_state(self):\n",
        "        \"easily get current state (score, apple, snake head and tail)\"\n",
        "        score = self.score\n",
        "        apple = self.apples\n",
        "        head = self.snake[0]\n",
        "        tail = self.snake[1:]\n",
        "        return score, apple, head, tail, self.direction\n",
        "\n",
        "    def print_state(self):\n",
        "        \"print the current board state\"\n",
        "        for i in range(self.height):\n",
        "            line = \".\" * self.width\n",
        "            for x, y in self.apples:\n",
        "                if y == i:\n",
        "                    line = line[:x] + \"A\" + line[x + 1 :]\n",
        "            for s in self.snake:\n",
        "                x, y = s\n",
        "                if y == i:\n",
        "                    line = line[:x] + \"X\" + line[x + 1 :]\n",
        "            print(line)\n",
        "\n",
        "    def test_step(self, direction):\n",
        "        \"to test: move the snake and print the game state\"\n",
        "        self.step(direction)\n",
        "        self.print_state()\n",
        "        if self.done:\n",
        "            print(\"Game over! Score=\", self.score)\n",
        "\n",
        "    def reset(self):\n",
        "        \"reset state\"\n",
        "        self.score = 0\n",
        "        self.done = False\n",
        "        self.create_snake()\n",
        "        self.apples = []\n",
        "        self.create_apples()\n",
        "        self.grass[:, :] = self.max_grass\n",
        "\n",
        "        return self.board_state(), 0, self.done, {\"score\": self.score}\n",
        "\n",
        "    def board_state(self, mode=\"human\", close=False):\n",
        "        \"Render the environment\"\n",
        "        self.board[:, :, :] = 0\n",
        "        if self.max_grass > 0:\n",
        "            self.board[:, :, 1] = self.grass / self.max_grass * 0.3\n",
        "        if not self.done:\n",
        "            x, y = self.snake[0]\n",
        "            self.board[x, y, :] = 1\n",
        "        for x, y in self.snake[1:]:\n",
        "            self.board[x, y, 0] = 1\n",
        "        for x, y in self.apples:\n",
        "            self.board[x, y, 1] = 1\n",
        "        if self.border == 0:\n",
        "            return self.board\n",
        "        else:\n",
        "            h, w, _ = self.board.shape\n",
        "            board = np.full(\n",
        "                (h + self.border * 2, w + self.border * 2, 3), 0.5, np.float32\n",
        "            )\n",
        "            board[self.border : -self.border, self.border : -self.border] = self.board\n",
        "            return board\n",
        "\n",
        "\n",
        "# just run this if this file is the main\n",
        "# if __name__ == '__main__':\n",
        "# game = SnakeGame(20,20)\n",
        "# game.print_state()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Heuristic approach using Manhattan distance"
      ],
      "metadata": {
        "id": "Ep69yyxqS1Lh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from math import fabs\n",
        "from copy import deepcopy\n",
        "\n",
        "class HeuristicAgent:\n",
        "    def __init__(self, env: SnakeGame):\n",
        "        self.env = env\n",
        "        self.possible_actions = [-1, 0, 1]\n",
        "\n",
        "    def generate_examples(self, n, force_trunc=False):\n",
        "        examples = []\n",
        "        while len(examples) < n:\n",
        "            transitions = self._play_game()\n",
        "            examples.extend(transitions)\n",
        "            print(f\"There are {len(examples)} examples\")\n",
        "        return examples[:n] if force_trunc else examples\n",
        "\n",
        "    def _play_game(self):\n",
        "        transitions = []\n",
        "        board_state, _, done, _ = self.env.reset()\n",
        "        steps = 0\n",
        "        total_reward = 0\n",
        "        while not done:\n",
        "            new_state, reward, done, _, action = self.pick_best_action(*self.env.get_state())\n",
        "            transition = (board_state, action, reward, new_state, done)\n",
        "            transitions.append(transition)\n",
        "            board_state = new_state\n",
        "            steps += 1\n",
        "            total_reward += reward\n",
        "            if steps % 100 == 0:\n",
        "                print(f\"Total reward = {total_reward} after {steps} steps\")\n",
        "        return transitions\n",
        "\n",
        "    def pick_best_action(self, score, apples, head, tail, direction):\n",
        "        closest_apple = min(apples, key=lambda apple: manh_dist(apple, head))\n",
        "        dying_penalty = max(self.env.width, self.env.height)**2\n",
        "        action_scores = []\n",
        "        for action in self.possible_actions:\n",
        "            _env = deepcopy(self.env)\n",
        "            _, reward, done, _ = _env.step(action)\n",
        "            if reward == 1:\n",
        "                action_score = 0\n",
        "            elif done:\n",
        "                action_score = dying_penalty\n",
        "            else:\n",
        "                _, _, new_head, _, _ = _env.get_state()\n",
        "                action_score = manh_dist(new_head, closest_apple)\n",
        "            action_scores.append(action_score)\n",
        "        min_score_index = action_scores.index(min(action_scores))\n",
        "        selected_action = self.possible_actions[min_score_index]\n",
        "        assert -1 <= selected_action <= 1\n",
        "        return (*self.env.step(selected_action), selected_action)\n",
        "\n",
        "\n",
        "def manh_dist(p1: tuple, p2: tuple):\n",
        "    x1, y1 = p1\n",
        "    x2, y2 = p2\n",
        "    return fabs(x1 - x2) + fabs(y1 - y2)"
      ],
      "metadata": {
        "id": "wRWF5TJwS0k-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "co7gC6FpNzTN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from collections import deque\n",
        "from typing import Iterable, List, Dict, Any\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from copy import deepcopy\n",
        "\n",
        "tf.config.run_functions_eagerly(True)\n",
        "\n",
        "class DqnAgent:\n",
        "    def __init__(\n",
        "        self,\n",
        "        env: SnakeGame,\n",
        "        possible_actions: List = [-1, 0, 1],\n",
        "        replay_memory_size: int = 2**16,\n",
        "    ):\n",
        "        self.env = env\n",
        "        self.possible_actions = possible_actions\n",
        "        self.state_shape = self.env.board_state().shape\n",
        "        self.model = self._create_model()\n",
        "        self.target_model = self._create_model()\n",
        "        self.target_model.set_weights(self.model.get_weights())\n",
        "        self.replay_memory = deque(maxlen=replay_memory_size)\n",
        "        self.rewards: List[float] = list()\n",
        "        self.steps_per_episode: List[int] = list()\n",
        "        self.data_to_log: List[Dict[str, Any]] = list()\n",
        "\n",
        "    def _create_model(self):\n",
        "      model = tf.keras.Sequential()\n",
        "      model.add(\n",
        "          tf.keras.layers.Conv2D(\n",
        "              filters=32,\n",
        "              kernel_size=(3, 3),\n",
        "              activation=\"relu\",\n",
        "              padding=\"same\",\n",
        "              kernel_initializer=tf.keras.initializers.HeNormal(),\n",
        "              input_shape=(24, 24, 3),\n",
        "          )\n",
        "      )\n",
        "      model.add(tf.keras.layers.BatchNormalization(synchronized=True))\n",
        "      model.add(\n",
        "          tf.keras.layers.Conv2D(\n",
        "              filters=64,\n",
        "              kernel_size=(3, 3),\n",
        "              activation=\"relu\",\n",
        "              padding=\"same\",\n",
        "              kernel_initializer=tf.keras.initializers.HeNormal(),\n",
        "          )\n",
        "      )\n",
        "      model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
        "      model.add(tf.keras.layers.BatchNormalization(synchronized=True))\n",
        "\n",
        "      model.add(tf.keras.layers.Flatten())\n",
        "      model.add(\n",
        "          tf.keras.layers.Dense(\n",
        "              64,\n",
        "              activation=\"relu\",\n",
        "              kernel_initializer=tf.keras.initializers.HeNormal(),\n",
        "          )\n",
        "      )\n",
        "      model.add(tf.keras.layers.BatchNormalization(synchronized=True))\n",
        "      model.add(\n",
        "          tf.keras.layers.Dense(\n",
        "              32,\n",
        "              activation=\"relu\",\n",
        "              kernel_initializer=tf.keras.initializers.HeNormal(),\n",
        "          )\n",
        "      )\n",
        "      model.add(tf.keras.layers.Dropout(.2))\n",
        "      model.add(tf.keras.layers.BatchNormalization(synchronized=True))\n",
        "      model.add(\n",
        "          tf.keras.layers.Dense(\n",
        "              3,\n",
        "              activation=\"linear\",\n",
        "              kernel_initializer=tf.keras.initializers.HeNormal(),\n",
        "          )\n",
        "      )\n",
        "      return model\n",
        "\n",
        "\n",
        "    def _train(self, done: bool, discount_factor: float, batch_size: int, epochs: int):\n",
        "        mini_batch = random.sample(self.replay_memory, batch_size)\n",
        "        current_states, actions, rewards, future_states, not_dones = [], [], [], [], []\n",
        "\n",
        "        for transition in mini_batch:\n",
        "            current_states.append(transition[0])\n",
        "            actions.append(self._action_index(transition[1]))\n",
        "            rewards.append(transition[2])\n",
        "            future_states.append(transition[3])\n",
        "            not_dones.append(int(not transition[4]))\n",
        "\n",
        "        current_states = np.array(current_states)\n",
        "        actions = np.array(actions)\n",
        "        rewards = np.array(rewards)\n",
        "        future_states = np.array(future_states)\n",
        "        not_dones = np.array(not_dones)\n",
        "\n",
        "        current_qs = self.model.predict(current_states)\n",
        "        future_qs = self.target_model.predict(future_states)\n",
        "        max_future_qs = rewards + discount_factor * np.max(future_qs, axis=1) * not_dones\n",
        "\n",
        "        current_qs[np.arange(len(current_qs)), actions] = max_future_qs\n",
        "\n",
        "        self.model.fit(\n",
        "            current_states, current_qs,\n",
        "            batch_size=64, shuffle=True, epochs=epochs\n",
        "        )\n",
        "\n",
        "\n",
        "    def train(\n",
        "        self,\n",
        "        episodes: int,\n",
        "        *,\n",
        "        min_epsilon: float,\n",
        "        max_epsilon: float,\n",
        "        decay: float,\n",
        "        learning_rate: float,\n",
        "        discount_factor: float,\n",
        "        epochs: int = 1000,\n",
        "        initial_examples: Iterable = list(),\n",
        "        batch_size: int = 512,\n",
        "        min_steps_to_update_target_model: int = 50,\n",
        "    ):\n",
        "        self._compile_model(learning_rate)\n",
        "        self.replay_memory.extend(initial_examples)\n",
        "        step_counter = 0\n",
        "        epsilon = max_epsilon\n",
        "        for episode in range(1, episodes + 1):\n",
        "            total_reward, steps_per_episode = 0, 0\n",
        "            state, _, done, _ = self.env.reset()\n",
        "            while not done:\n",
        "                step_counter += 1\n",
        "                steps_per_episode += 1\n",
        "                action = self._epsilon_greedy_action(epsilon, state)\n",
        "                next_state, reward, done, _ = self.env.step(action)\n",
        "                self.replay_memory.append((state, action, reward, next_state, done))\n",
        "                if step_counter % 4 == 0 or done:\n",
        "                    self._train(done, discount_factor, batch_size, epochs)\n",
        "                state = next_state\n",
        "                total_reward += reward\n",
        "                if done:\n",
        "                    self._print_episode_info(episode, total_reward, steps_per_episode)\n",
        "                    self._update_reward_history(step_counter, total_reward)\n",
        "                    self._update_target_model(step_counter, min_steps_to_update_target_model)\n",
        "            epsilon = self._generate_epsilon(epsilon, min_epsilon, max_epsilon, decay)\n",
        "\n",
        "    def _compile_model(self, learning_rate):\n",
        "        self.model.compile(loss=\"mse\", optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), run_eagerly=False)\n",
        "\n",
        "    def _train_model(self, done, discount_factor, batch_size, epochs):\n",
        "        self._train(done, discount_factor, batch_size, epochs=epochs)  # done, env, replay_memory, model, target_model, epochs\n",
        "\n",
        "    def _print_episode_info(self, episode, total_reward, steps_per_episode):\n",
        "        print(f\"------ Episode {episode} reward = {total_reward} steps = {steps_per_episode} -------\")\n",
        "\n",
        "    def _update_reward_history(self, step_counter, total_reward):\n",
        "        self.rewards.append(total_reward)\n",
        "        self.steps_per_episode.append(step_counter)\n",
        "\n",
        "    def _update_target_model(self, step_counter, min_steps_to_update_target_model):\n",
        "        if step_counter >= min_steps_to_update_target_model:\n",
        "            self.target_model.set_weights(self.model.get_weights())\n",
        "            step_counter = 0\n",
        "\n",
        "    def _generate_epsilon(self, previous_epsilon, min_epsilon, max_epsilon, decay):\n",
        "        new_epsilon = min_epsilon + (max_epsilon - min_epsilon) * np.exp(-decay * previous_epsilon)\n",
        "        return new_epsilon\n",
        "\n",
        "\n",
        "    def play_game(self):\n",
        "        state, _, done, _ = self.env.reset()\n",
        "        self.env.print_state()\n",
        "        total_reward = 0\n",
        "        while not done:\n",
        "            state_reshaped = state.reshape((1, *state.shape))\n",
        "            predicted_q_values = self.model.predict(state_reshaped).flatten()\n",
        "            action = self._choose_action(predicted_q_values)\n",
        "            state, reward, done, _ = self.env.step(action)\n",
        "            total_reward += reward\n",
        "            self.env.print_state()\n",
        "        return total_reward\n",
        "\n",
        "    def _epsilon_greedy_action(self, epsilon, state) -> int:\n",
        "        if np.random.rand() <= epsilon:\n",
        "            action = np.random.choice(self.possible_actions)\n",
        "        else:\n",
        "            state_reshaped = state.reshape((1, *state.shape))\n",
        "            predicted_q_values = self.model.predict(state_reshaped).flatten()\n",
        "            action = self._choose_action(predicted_q_values)\n",
        "        return action\n",
        "\n",
        "    def _choose_action(self, q_values: np.ndarray):\n",
        "        action_index = np.argmax(q_values)\n",
        "        action = self.possible_actions[action_index]\n",
        "        # assert -1 <= action <= 1\n",
        "        return action\n",
        "\n",
        "    def _action_index(self, action: int) -> int:\n",
        "        index = self.possible_actions.index(action)\n",
        "        assert 0 <= index <= 2\n",
        "        return index\n",
        "\n",
        "    def plot_rewards(self):\n",
        "        episodes = range(1, len(self.rewards) + 1)\n",
        "        plt.plot(episodes, self.rewards)\n",
        "        plt.xlabel(\"Episode\")\n",
        "        plt.ylabel(\"Total Reward\")\n",
        "        plt.title(\"Total Reward per Episode\")\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "BkeWcYvoNylh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#agent.env.board_state().shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ux9-lUo5N4pF",
        "outputId": "ec35629c-01b1-41c6-9f4b-02b8c3ec0989"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24, 24, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating game and training\n"
      ],
      "metadata": {
        "id": "jvRcpXLWzuJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "game = SnakeGame(\n",
        "    width=14, height=14, border=5, food_amount=1, grass_growth=0.001, max_grass=0.05\n",
        ")\n",
        "state_shape = game.board_state().shape\n",
        "possible_actions = [-1, 0, 1]"
      ],
      "metadata": {
        "id": "ufvI5M--zwMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "huristic = HeuristicAgent(game)\n",
        "initial_examples = huristic.generate_examples(10**5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "purqyZpizztf",
        "outputId": "99216a38-03e5-4270-b7ad-fe56fce08259"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total reward = 14.618000000000025 after 100 steps\n",
            "Total reward = 28.412000000000088 after 200 steps\n",
            "Total reward = 40.05799999999995 after 300 steps\n",
            "Total reward = 51.031999999999684 after 400 steps\n",
            "There are 490 examples\n",
            "Total reward = 13.54400000000001 after 100 steps\n",
            "Total reward = 27.08200000000004 after 200 steps\n",
            "Total reward = 39.58199999999988 after 300 steps\n",
            "Total reward = 50.40399999999967 after 400 steps\n",
            "There are 934 examples\n",
            "Total reward = 15.634000000000027 after 100 steps\n",
            "There are 1114 examples\n",
            "Total reward = 16.690000000000015 after 100 steps\n",
            "Total reward = 27.138000000000062 after 200 steps\n",
            "There are 1361 examples\n",
            "Total reward = 14.381999999999996 after 100 steps\n",
            "Total reward = 29.11200000000005 after 200 steps\n",
            "Total reward = 41.731999999999886 after 300 steps\n",
            "Total reward = 51.49999999999962 after 400 steps\n",
            "There are 1772 examples\n",
            "Total reward = 15.500000000000032 after 100 steps\n",
            "Total reward = 31.128000000000085 after 200 steps\n",
            "There are 1973 examples\n",
            "Total reward = 17.47400000000003 after 100 steps\n",
            "There are 2134 examples\n",
            "Total reward = 15.754000000000023 after 100 steps\n",
            "Total reward = 30.494000000000074 after 200 steps\n",
            "There are 2395 examples\n",
            "Total reward = 15.652000000000017 after 100 steps\n",
            "There are 2575 examples\n",
            "Total reward = 17.75000000000002 after 100 steps\n",
            "Total reward = 31.604000000000088 after 200 steps\n",
            "Total reward = 47.50399999999983 after 300 steps\n",
            "There are 2961 examples\n",
            "Total reward = 15.844000000000019 after 100 steps\n",
            "Total reward = 30.29000000000007 after 200 steps\n",
            "There are 3217 examples\n",
            "Total reward = 14.656000000000011 after 100 steps\n",
            "There are 3411 examples\n",
            "Total reward = 15.476000000000022 after 100 steps\n",
            "Total reward = 27.318000000000087 after 200 steps\n",
            "There are 3628 examples\n",
            "Total reward = 14.684000000000024 after 100 steps\n",
            "There are 3761 examples\n",
            "Total reward = 16.728000000000023 after 100 steps\n",
            "Total reward = 27.324000000000073 after 200 steps\n",
            "There are 3980 examples\n",
            "Total reward = 15.592000000000018 after 100 steps\n",
            "There are 4155 examples\n",
            "Total reward = 14.820000000000029 after 100 steps\n",
            "Total reward = 28.56000000000009 after 200 steps\n",
            "There are 4394 examples\n",
            "Total reward = 16.716000000000022 after 100 steps\n",
            "There are 4495 examples\n",
            "There are 4566 examples\n",
            "Total reward = 13.522000000000022 after 100 steps\n",
            "Total reward = 28.29800000000008 after 200 steps\n",
            "There are 4809 examples\n",
            "Total reward = 16.32200000000002 after 100 steps\n",
            "Total reward = 29.068000000000072 after 200 steps\n",
            "Total reward = 42.02199999999986 after 300 steps\n",
            "There are 5139 examples\n",
            "Total reward = 12.594000000000017 after 100 steps\n",
            "Total reward = 22.16000000000007 after 200 steps\n",
            "There are 5437 examples\n",
            "Total reward = 15.510000000000023 after 100 steps\n",
            "Total reward = 33.098000000000035 after 200 steps\n",
            "There are 5678 examples\n",
            "Total reward = 15.754000000000019 after 100 steps\n",
            "There are 5815 examples\n",
            "Total reward = 13.888000000000025 after 100 steps\n",
            "There are 5990 examples\n",
            "Total reward = 16.388000000000016 after 100 steps\n",
            "There are 6157 examples\n",
            "Total reward = 17.58400000000002 after 100 steps\n",
            "Total reward = 31.420000000000083 after 200 steps\n",
            "There are 6391 examples\n",
            "Total reward = 16.89800000000002 after 100 steps\n",
            "Total reward = 29.762000000000068 after 200 steps\n",
            "Total reward = 42.57999999999987 after 300 steps\n",
            "There are 6691 examples\n",
            "Total reward = 16.668000000000028 after 100 steps\n",
            "Total reward = 28.322000000000084 after 200 steps\n",
            "There are 6893 examples\n",
            "Total reward = 16.58200000000002 after 100 steps\n",
            "Total reward = 32.892000000000046 after 200 steps\n",
            "There are 7156 examples\n",
            "Total reward = 17.560000000000016 after 100 steps\n",
            "Total reward = 30.002000000000066 after 200 steps\n",
            "Total reward = 41.79399999999986 after 300 steps\n",
            "There are 7474 examples\n",
            "Total reward = 17.57000000000002 after 100 steps\n",
            "Total reward = 30.336000000000087 after 200 steps\n",
            "There are 7716 examples\n",
            "Total reward = 17.720000000000013 after 100 steps\n",
            "Total reward = 33.16800000000004 after 200 steps\n",
            "There are 8001 examples\n",
            "Total reward = 13.650000000000022 after 100 steps\n",
            "Total reward = 27.31600000000008 after 200 steps\n",
            "There are 8289 examples\n",
            "Total reward = 15.714000000000027 after 100 steps\n",
            "Total reward = 25.408000000000087 after 200 steps\n",
            "There are 8551 examples\n",
            "Total reward = 15.712000000000033 after 100 steps\n",
            "Total reward = 31.414000000000097 after 200 steps\n",
            "There are 8756 examples\n",
            "Total reward = 17.64600000000003 after 100 steps\n",
            "There are 8948 examples\n",
            "Total reward = 15.664000000000023 after 100 steps\n",
            "Total reward = 29.334000000000096 after 200 steps\n",
            "There are 9154 examples\n",
            "Total reward = 13.682000000000015 after 100 steps\n",
            "Total reward = 28.606000000000055 after 200 steps\n",
            "There are 9380 examples\n",
            "Total reward = 15.750000000000018 after 100 steps\n",
            "There are 9567 examples\n",
            "Total reward = 18.754000000000023 after 100 steps\n",
            "Total reward = 29.51800000000008 after 200 steps\n",
            "There are 9858 examples\n",
            "Total reward = 14.802000000000021 after 100 steps\n",
            "Total reward = 28.624000000000084 after 200 steps\n",
            "There are 10123 examples\n",
            "There are 10219 examples\n",
            "There are 10311 examples\n",
            "Total reward = 14.532000000000012 after 100 steps\n",
            "Total reward = 29.174000000000063 after 200 steps\n",
            "Total reward = 42.95599999999988 after 300 steps\n",
            "There are 10645 examples\n",
            "Total reward = 15.80200000000002 after 100 steps\n",
            "Total reward = 33.61000000000003 after 200 steps\n",
            "Total reward = 48.57799999999976 after 300 steps\n",
            "There are 10964 examples\n",
            "Total reward = 14.786000000000012 after 100 steps\n",
            "Total reward = 27.462000000000067 after 200 steps\n",
            "Total reward = 40.31599999999991 after 300 steps\n",
            "There are 11289 examples\n",
            "Total reward = 14.660000000000029 after 100 steps\n",
            "There are 11414 examples\n",
            "Total reward = 14.68000000000001 after 100 steps\n",
            "Total reward = 26.25400000000007 after 200 steps\n",
            "Total reward = 43.15599999999992 after 300 steps\n",
            "There are 11720 examples\n",
            "Total reward = 14.614000000000015 after 100 steps\n",
            "Total reward = 27.49200000000008 after 200 steps\n",
            "There are 11927 examples\n",
            "Total reward = 13.806000000000015 after 100 steps\n",
            "Total reward = 30.610000000000074 after 200 steps\n",
            "Total reward = 42.54599999999989 after 300 steps\n",
            "There are 12234 examples\n",
            "Total reward = 13.684000000000015 after 100 steps\n",
            "There are 12411 examples\n",
            "Total reward = 15.53400000000003 after 100 steps\n",
            "Total reward = 30.248000000000093 after 200 steps\n",
            "There are 12681 examples\n",
            "Total reward = 16.67800000000003 after 100 steps\n",
            "Total reward = 29.334000000000074 after 200 steps\n",
            "Total reward = 40.08999999999989 after 300 steps\n",
            "There are 13022 examples\n",
            "Total reward = 18.830000000000034 after 100 steps\n",
            "There are 13193 examples\n",
            "Total reward = 13.764000000000015 after 100 steps\n",
            "Total reward = 27.130000000000074 after 200 steps\n",
            "Total reward = 37.894 after 300 steps\n",
            "Total reward = 50.57599999999983 after 400 steps\n",
            "Total reward = 61.31599999999966 after 500 steps\n",
            "Total reward = 72.2619999999995 after 600 steps\n",
            "Total reward = 87.26199999999922 after 700 steps\n",
            "There are 13932 examples\n",
            "Total reward = 17.356 after 100 steps\n",
            "Total reward = 33.13600000000005 after 200 steps\n",
            "Total reward = 47.92999999999982 after 300 steps\n",
            "There are 14322 examples\n",
            "Total reward = 13.770000000000016 after 100 steps\n",
            "Total reward = 27.60800000000008 after 200 steps\n",
            "Total reward = 40.40999999999993 after 300 steps\n",
            "Total reward = 47.96599999999973 after 400 steps\n",
            "Total reward = 55.83399999999951 after 500 steps\n",
            "There are 14901 examples\n",
            "Total reward = 13.42000000000001 after 100 steps\n",
            "There are 15043 examples\n",
            "Total reward = 15.786000000000028 after 100 steps\n",
            "Total reward = 27.516000000000087 after 200 steps\n",
            "Total reward = 42.309999999999924 after 300 steps\n",
            "There are 15398 examples\n",
            "Total reward = 14.59200000000001 after 100 steps\n",
            "Total reward = 27.20800000000006 after 200 steps\n",
            "Total reward = 42.72199999999993 after 300 steps\n",
            "There are 15768 examples\n",
            "Total reward = 14.970000000000018 after 100 steps\n",
            "Total reward = 29.57200000000008 after 200 steps\n",
            "Total reward = 40.2719999999999 after 300 steps\n",
            "Total reward = 49.09399999999964 after 400 steps\n",
            "Total reward = 59.05199999999936 after 500 steps\n",
            "There are 16303 examples\n",
            "Total reward = 13.288000000000011 after 100 steps\n",
            "Total reward = 28.126000000000076 after 200 steps\n",
            "Total reward = 41.027999999999906 after 300 steps\n",
            "There are 16675 examples\n",
            "Total reward = 13.506000000000025 after 100 steps\n",
            "There are 16847 examples\n",
            "Total reward = 14.664000000000025 after 100 steps\n",
            "Total reward = 27.332000000000082 after 200 steps\n",
            "There are 17076 examples\n",
            "Total reward = 13.674000000000014 after 100 steps\n",
            "Total reward = 27.374000000000063 after 200 steps\n",
            "There are 17276 examples\n",
            "There are 17327 examples\n",
            "There are 17413 examples\n",
            "Total reward = 17.74000000000002 after 100 steps\n",
            "Total reward = 31.21600000000006 after 200 steps\n",
            "Total reward = 46.15399999999979 after 300 steps\n",
            "Total reward = 57.913999999999554 after 400 steps\n",
            "Total reward = 67.90199999999929 after 500 steps\n",
            "There are 17942 examples\n",
            "Total reward = 15.946000000000033 after 100 steps\n",
            "Total reward = 28.7860000000001 after 200 steps\n",
            "There are 18207 examples\n",
            "Total reward = 15.898000000000028 after 100 steps\n",
            "There are 18355 examples\n",
            "Total reward = 13.762000000000018 after 100 steps\n",
            "Total reward = 25.278000000000056 after 200 steps\n",
            "Total reward = 44.165999999999904 after 300 steps\n",
            "There are 18676 examples\n",
            "Total reward = 13.684000000000015 after 100 steps\n",
            "Total reward = 29.26800000000006 after 200 steps\n",
            "Total reward = 42.0419999999999 after 300 steps\n",
            "Total reward = 55.01199999999963 after 400 steps\n",
            "There are 19080 examples\n",
            "Total reward = 14.750000000000021 after 100 steps\n",
            "There are 19260 examples\n",
            "Total reward = 15.606000000000014 after 100 steps\n",
            "There are 19381 examples\n",
            "Total reward = 15.134 after 100 steps\n",
            "There are 19483 examples\n",
            "Total reward = 15.654000000000021 after 100 steps\n",
            "Total reward = 30.338000000000083 after 200 steps\n",
            "There are 19735 examples\n",
            "Total reward = 14.704000000000024 after 100 steps\n",
            "Total reward = 32.56400000000008 after 200 steps\n",
            "There are 20020 examples\n",
            "Total reward = 15.916000000000029 after 100 steps\n",
            "Total reward = 29.622000000000032 after 200 steps\n",
            "Total reward = 44.57399999999982 after 300 steps\n",
            "There are 20407 examples\n",
            "Total reward = 14.678000000000013 after 100 steps\n",
            "Total reward = 30.374000000000084 after 200 steps\n",
            "There are 20687 examples\n",
            "Total reward = 13.844000000000017 after 100 steps\n",
            "There are 20879 examples\n",
            "Total reward = 16.77400000000003 after 100 steps\n",
            "Total reward = 31.530000000000094 after 200 steps\n",
            "There are 21169 examples\n",
            "Total reward = 16.52200000000002 after 100 steps\n",
            "Total reward = 28.342000000000077 after 200 steps\n",
            "There are 21455 examples\n",
            "Total reward = 16.612000000000023 after 100 steps\n",
            "Total reward = 31.380000000000084 after 200 steps\n",
            "Total reward = 41.21199999999989 after 300 steps\n",
            "Total reward = 51.127999999999616 after 400 steps\n",
            "There are 21880 examples\n",
            "Total reward = 14.648000000000014 after 100 steps\n",
            "Total reward = 31.494000000000078 after 200 steps\n",
            "There are 22167 examples\n",
            "Total reward = 17.76600000000002 after 100 steps\n",
            "Total reward = 32.374000000000066 after 200 steps\n",
            "Total reward = 45.31399999999978 after 300 steps\n",
            "There are 22504 examples\n",
            "Total reward = 14.854000000000024 after 100 steps\n",
            "There are 22662 examples\n",
            "Total reward = 14.500000000000018 after 100 steps\n",
            "Total reward = 32.23600000000007 after 200 steps\n",
            "Total reward = 45.17399999999979 after 300 steps\n",
            "There are 23030 examples\n",
            "Total reward = 14.77600000000001 after 100 steps\n",
            "There are 23218 examples\n",
            "Total reward = 16.33200000000002 after 100 steps\n",
            "Total reward = 30.176000000000087 after 200 steps\n",
            "There are 23469 examples\n",
            "Total reward = 14.67000000000002 after 100 steps\n",
            "Total reward = 26.460000000000086 after 200 steps\n",
            "Total reward = 39.26799999999994 after 300 steps\n",
            "There are 23846 examples\n",
            "Total reward = 15.668000000000028 after 100 steps\n",
            "Total reward = 25.020000000000078 after 200 steps\n",
            "Total reward = 36.830000000000005 after 300 steps\n",
            "Total reward = 50.73399999999974 after 400 steps\n",
            "There are 24332 examples\n",
            "Total reward = 15.468000000000016 after 100 steps\n",
            "There are 24441 examples\n",
            "Total reward = 14.664000000000026 after 100 steps\n",
            "Total reward = 26.556000000000093 after 200 steps\n",
            "Total reward = 41.36599999999994 after 300 steps\n",
            "Total reward = 51.29599999999969 after 400 steps\n",
            "Total reward = 68.2799999999994 after 500 steps\n",
            "There are 24963 examples\n",
            "Total reward = 13.366000000000025 after 100 steps\n",
            "Total reward = 29.20400000000009 after 200 steps\n",
            "Total reward = 41.95799999999994 after 300 steps\n",
            "There are 25265 examples\n",
            "Total reward = 13.612000000000021 after 100 steps\n",
            "There are 25444 examples\n",
            "Total reward = 12.746000000000018 after 100 steps\n",
            "Total reward = 26.400000000000073 after 200 steps\n",
            "Total reward = 35.11200000000005 after 300 steps\n",
            "Total reward = 47.087999999999774 after 400 steps\n",
            "There are 25892 examples\n",
            "Total reward = 16.65400000000003 after 100 steps\n",
            "Total reward = 33.470000000000056 after 200 steps\n",
            "There are 26121 examples\n",
            "Total reward = 12.816000000000017 after 100 steps\n",
            "Total reward = 29.60400000000008 after 200 steps\n",
            "There are 26345 examples\n",
            "Total reward = 16.708000000000027 after 100 steps\n",
            "Total reward = 30.626000000000097 after 200 steps\n",
            "There are 26586 examples\n",
            "Total reward = 13.546000000000022 after 100 steps\n",
            "Total reward = 26.12200000000006 after 200 steps\n",
            "Total reward = 40.04399999999994 after 300 steps\n",
            "There are 26915 examples\n",
            "Total reward = 14.608000000000022 after 100 steps\n",
            "There are 27051 examples\n",
            "Total reward = 13.734000000000018 after 100 steps\n",
            "Total reward = 26.450000000000074 after 200 steps\n",
            "Total reward = 39.27399999999997 after 300 steps\n",
            "Total reward = 47.14399999999971 after 400 steps\n",
            "There are 27480 examples\n",
            "Total reward = 15.776000000000023 after 100 steps\n",
            "Total reward = 33.60600000000006 after 200 steps\n",
            "There are 27715 examples\n",
            "Total reward = 17.880000000000027 after 100 steps\n",
            "Total reward = 33.684000000000054 after 200 steps\n",
            "There are 27973 examples\n",
            "Total reward = 16.698000000000015 after 100 steps\n",
            "There are 28130 examples\n",
            "Total reward = 14.900000000000015 after 100 steps\n",
            "There are 28258 examples\n",
            "Total reward = 14.472000000000028 after 100 steps\n",
            "Total reward = 29.246000000000095 after 200 steps\n",
            "There are 28477 examples\n",
            "Total reward = 14.628000000000027 after 100 steps\n",
            "Total reward = 32.34800000000007 after 200 steps\n",
            "Total reward = 49.22799999999984 after 300 steps\n",
            "Total reward = 58.21199999999956 after 400 steps\n",
            "There are 28897 examples\n",
            "Total reward = 13.260000000000014 after 100 steps\n",
            "There are 29081 examples\n",
            "Total reward = 15.462000000000026 after 100 steps\n",
            "Total reward = 28.102000000000082 after 200 steps\n",
            "There are 29342 examples\n",
            "Total reward = 17.852000000000018 after 100 steps\n",
            "Total reward = 31.590000000000067 after 200 steps\n",
            "There are 29590 examples\n",
            "Total reward = 14.822000000000019 after 100 steps\n",
            "Total reward = 27.646000000000075 after 200 steps\n",
            "Total reward = 40.275999999999904 after 300 steps\n",
            "Total reward = 51.19599999999971 after 400 steps\n",
            "Total reward = 63.17999999999943 after 500 steps\n",
            "There are 30169 examples\n",
            "Total reward = 12.79400000000002 after 100 steps\n",
            "Total reward = 26.48600000000008 after 200 steps\n",
            "There are 30421 examples\n",
            "Total reward = 16.45600000000002 after 100 steps\n",
            "Total reward = 31.048000000000076 after 200 steps\n",
            "There are 30697 examples\n",
            "Total reward = 15.85400000000003 after 100 steps\n",
            "Total reward = 26.73400000000009 after 200 steps\n",
            "Total reward = 43.42399999999993 after 300 steps\n",
            "There are 31045 examples\n",
            "Total reward = 13.518000000000013 after 100 steps\n",
            "There are 31168 examples\n",
            "Total reward = 14.698000000000022 after 100 steps\n",
            "Total reward = 29.30000000000007 after 200 steps\n",
            "There are 31371 examples\n",
            "Total reward = 14.396000000000008 after 100 steps\n",
            "Total reward = 32.27800000000006 after 200 steps\n",
            "Total reward = 44.089999999999826 after 300 steps\n",
            "Total reward = 56.069999999999546 after 400 steps\n",
            "There are 31776 examples\n",
            "Total reward = 12.838000000000013 after 100 steps\n",
            "Total reward = 26.344000000000054 after 200 steps\n",
            "There are 32066 examples\n",
            "There are 32147 examples\n",
            "Total reward = 15.55600000000002 after 100 steps\n",
            "There are 32332 examples\n",
            "Total reward = 15.050000000000022 after 100 steps\n",
            "Total reward = 29.612000000000066 after 200 steps\n",
            "Total reward = 41.30399999999991 after 300 steps\n",
            "There are 32730 examples\n",
            "Total reward = 16.486000000000026 after 100 steps\n",
            "Total reward = 28.13400000000009 after 200 steps\n",
            "There are 32997 examples\n",
            "Total reward = 13.642000000000019 after 100 steps\n",
            "Total reward = 27.23400000000007 after 200 steps\n",
            "Total reward = 41.11199999999994 after 300 steps\n",
            "Total reward = 51.84199999999967 after 400 steps\n",
            "There are 33417 examples\n",
            "Total reward = 16.772000000000027 after 100 steps\n",
            "There are 33555 examples\n",
            "Total reward = 14.792000000000023 after 100 steps\n",
            "Total reward = 32.420000000000044 after 200 steps\n",
            "There are 33763 examples\n",
            "Total reward = 13.600000000000021 after 100 steps\n",
            "There are 33903 examples\n",
            "Total reward = 15.784000000000018 after 100 steps\n",
            "Total reward = 27.994000000000053 after 200 steps\n",
            "Total reward = 38.85799999999987 after 300 steps\n",
            "Total reward = 49.405999999999636 after 400 steps\n",
            "Total reward = 58.367999999999356 after 500 steps\n",
            "Total reward = 70.23999999999918 after 600 steps\n",
            "There are 34509 examples\n",
            "Total reward = 13.458000000000014 after 100 steps\n",
            "Total reward = 28.89600000000008 after 200 steps\n",
            "Total reward = 40.86999999999988 after 300 steps\n",
            "Total reward = 51.801999999999616 after 400 steps\n",
            "There are 34963 examples\n",
            "Total reward = 18.546000000000017 after 100 steps\n",
            "Total reward = 33.19800000000005 after 200 steps\n",
            "Total reward = 47.999999999999815 after 300 steps\n",
            "Total reward = 56.991999999999535 after 400 steps\n",
            "There are 35406 examples\n",
            "Total reward = 14.880000000000017 after 100 steps\n",
            "Total reward = 26.476000000000074 after 200 steps\n",
            "Total reward = 44.37799999999995 after 300 steps\n",
            "There are 35740 examples\n",
            "Total reward = 15.802000000000026 after 100 steps\n",
            "There are 35920 examples\n",
            "Total reward = 16.744000000000025 after 100 steps\n",
            "Total reward = 34.66400000000003 after 200 steps\n",
            "Total reward = 48.6039999999998 after 300 steps\n",
            "There are 36225 examples\n",
            "Total reward = 13.768000000000022 after 100 steps\n",
            "There are 36422 examples\n",
            "Total reward = 14.710000000000017 after 100 steps\n",
            "Total reward = 28.24200000000005 after 200 steps\n",
            "Total reward = 38.77000000000002 after 300 steps\n",
            "There are 36732 examples\n",
            "Total reward = 16.61600000000002 after 100 steps\n",
            "Total reward = 31.346000000000075 after 200 steps\n",
            "Total reward = 44.21799999999987 after 300 steps\n",
            "There are 37063 examples\n",
            "Total reward = 15.770000000000028 after 100 steps\n",
            "Total reward = 27.306000000000083 after 200 steps\n",
            "Total reward = 37.239999999999924 after 300 steps\n",
            "There are 37364 examples\n",
            "Total reward = 16.446000000000016 after 100 steps\n",
            "There are 37537 examples\n",
            "Total reward = 16.374000000000024 after 100 steps\n",
            "Total reward = 31.004000000000065 after 200 steps\n",
            "Total reward = 41.7159999999999 after 300 steps\n",
            "Total reward = 53.61199999999965 after 400 steps\n",
            "There are 37942 examples\n",
            "Total reward = 16.79200000000002 after 100 steps\n",
            "Total reward = 32.45000000000006 after 200 steps\n",
            "Total reward = 41.373999999999796 after 300 steps\n",
            "There are 38294 examples\n",
            "Total reward = 16.592000000000024 after 100 steps\n",
            "Total reward = 28.12400000000008 after 200 steps\n",
            "Total reward = 38.77199999999991 after 300 steps\n",
            "There are 38648 examples\n",
            "Total reward = 14.744000000000021 after 100 steps\n",
            "Total reward = 31.66600000000009 after 200 steps\n",
            "Total reward = 43.50199999999985 after 300 steps\n",
            "Total reward = 53.45799999999959 after 400 steps\n",
            "Total reward = 62.42599999999933 after 500 steps\n",
            "There are 39233 examples\n",
            "Total reward = 12.356000000000005 after 100 steps\n",
            "Total reward = 29.15200000000007 after 200 steps\n",
            "Total reward = 42.96799999999987 after 300 steps\n",
            "Total reward = 55.905999999999615 after 400 steps\n",
            "There are 39665 examples\n",
            "Total reward = 15.840000000000027 after 100 steps\n",
            "There are 39825 examples\n",
            "Total reward = 14.67000000000002 after 100 steps\n",
            "Total reward = 30.370000000000072 after 200 steps\n",
            "There are 40047 examples\n",
            "Total reward = 14.360000000000015 after 100 steps\n",
            "Total reward = 28.092000000000084 after 200 steps\n",
            "Total reward = 39.84599999999998 after 300 steps\n",
            "Total reward = 49.83599999999971 after 400 steps\n",
            "There are 40509 examples\n",
            "There are 40607 examples\n",
            "Total reward = 17.702000000000012 after 100 steps\n",
            "Total reward = 32.64000000000007 after 200 steps\n",
            "There are 40833 examples\n",
            "Total reward = 12.742000000000022 after 100 steps\n",
            "There are 40963 examples\n",
            "There are 41054 examples\n",
            "Total reward = 18.526000000000007 after 100 steps\n",
            "There are 41165 examples\n",
            "Total reward = 16.478000000000026 after 100 steps\n",
            "Total reward = 28.108000000000082 after 200 steps\n",
            "Total reward = 40.95199999999993 after 300 steps\n",
            "Total reward = 52.81199999999967 after 400 steps\n",
            "There are 41629 examples\n",
            "Total reward = 13.88400000000002 after 100 steps\n",
            "There are 41773 examples\n",
            "Total reward = 17.46800000000001 after 100 steps\n",
            "There are 41960 examples\n",
            "Total reward = 16.504000000000026 after 100 steps\n",
            "There are 42092 examples\n",
            "Total reward = 12.960000000000017 after 100 steps\n",
            "Total reward = 28.446000000000048 after 200 steps\n",
            "There are 42365 examples\n",
            "Total reward = 17.478000000000016 after 100 steps\n",
            "Total reward = 29.060000000000056 after 200 steps\n",
            "There are 42604 examples\n",
            "Total reward = 14.631999999999998 after 100 steps\n",
            "There are 42783 examples\n",
            "Total reward = 15.53200000000002 after 100 steps\n",
            "Total reward = 29.110000000000085 after 200 steps\n",
            "There are 43015 examples\n",
            "Total reward = 14.758000000000031 after 100 steps\n",
            "There are 43211 examples\n",
            "Total reward = 14.490000000000022 after 100 steps\n",
            "Total reward = 29.46000000000009 after 200 steps\n",
            "There are 43433 examples\n",
            "Total reward = 16.586000000000023 after 100 steps\n",
            "Total reward = 31.02200000000005 after 200 steps\n",
            "There are 43644 examples\n",
            "Total reward = 18.74800000000003 after 100 steps\n",
            "Total reward = 33.470000000000056 after 200 steps\n",
            "Total reward = 46.217999999999805 after 300 steps\n",
            "There are 44023 examples\n",
            "Total reward = 14.730000000000018 after 100 steps\n",
            "Total reward = 32.38800000000007 after 200 steps\n",
            "There are 44309 examples\n",
            "Total reward = 17.790000000000024 after 100 steps\n",
            "There are 44413 examples\n",
            "Total reward = 14.858000000000017 after 100 steps\n",
            "Total reward = 31.75800000000008 after 200 steps\n",
            "Total reward = 41.64599999999984 after 300 steps\n",
            "Total reward = 50.60199999999958 after 400 steps\n",
            "Total reward = 60.55399999999931 after 500 steps\n",
            "There are 44992 examples\n",
            "Total reward = 13.80800000000002 after 100 steps\n",
            "Total reward = 27.350000000000072 after 200 steps\n",
            "There are 45260 examples\n",
            "Total reward = 15.894000000000029 after 100 steps\n",
            "There are 45457 examples\n",
            "Total reward = 14.740000000000025 after 100 steps\n",
            "There are 45618 examples\n",
            "There are 45702 examples\n",
            "Total reward = 13.788000000000013 after 100 steps\n",
            "Total reward = 26.396000000000054 after 200 steps\n",
            "There are 45933 examples\n",
            "Total reward = 15.630000000000013 after 100 steps\n",
            "Total reward = 29.352000000000057 after 200 steps\n",
            "There are 46217 examples\n",
            "Total reward = 16.652000000000026 after 100 steps\n",
            "Total reward = 30.51800000000008 after 200 steps\n",
            "Total reward = 43.347999999999864 after 300 steps\n",
            "There are 46561 examples\n",
            "There are 46595 examples\n",
            "Total reward = 15.528000000000013 after 100 steps\n",
            "Total reward = 33.19200000000005 after 200 steps\n",
            "There are 46802 examples\n",
            "Total reward = 11.798000000000012 after 100 steps\n",
            "Total reward = 23.150000000000066 after 200 steps\n",
            "There are 47017 examples\n",
            "Total reward = 13.812000000000017 after 100 steps\n",
            "Total reward = 26.504000000000072 after 200 steps\n",
            "There are 47302 examples\n",
            "Total reward = 17.48000000000003 after 100 steps\n",
            "Total reward = 36.28799999999998 after 200 steps\n",
            "There are 47541 examples\n",
            "Total reward = 16.51800000000003 after 100 steps\n",
            "Total reward = 27.416000000000093 after 200 steps\n",
            "There are 47830 examples\n",
            "Total reward = 16.720000000000017 after 100 steps\n",
            "Total reward = 28.482000000000077 after 200 steps\n",
            "Total reward = 37.27399999999999 after 300 steps\n",
            "Total reward = 54.181999999999725 after 400 steps\n",
            "There are 48231 examples\n",
            "Total reward = 16.362000000000027 after 100 steps\n",
            "There are 48394 examples\n",
            "Total reward = 15.082000000000026 after 100 steps\n",
            "There are 48503 examples\n",
            "Total reward = 14.912000000000027 after 100 steps\n",
            "Total reward = 26.408000000000083 after 200 steps\n",
            "Total reward = 40.059999999999995 after 300 steps\n",
            "Total reward = 50.03399999999972 after 400 steps\n",
            "There are 48945 examples\n",
            "Total reward = 14.382000000000014 after 100 steps\n",
            "Total reward = 29.264000000000085 after 200 steps\n",
            "There are 49222 examples\n",
            "Total reward = 15.828000000000015 after 100 steps\n",
            "Total reward = 29.562000000000076 after 200 steps\n",
            "Total reward = 42.289999999999864 after 300 steps\n",
            "There are 49554 examples\n",
            "Total reward = 15.400000000000013 after 100 steps\n",
            "There are 49743 examples\n",
            "Total reward = 14.398000000000012 after 100 steps\n",
            "There are 49934 examples\n",
            "Total reward = 14.480000000000015 after 100 steps\n",
            "Total reward = 29.346000000000085 after 200 steps\n",
            "Total reward = 40.03799999999994 after 300 steps\n",
            "There are 50303 examples\n",
            "Total reward = 14.676000000000013 after 100 steps\n",
            "There are 50421 examples\n",
            "Total reward = 15.472000000000026 after 100 steps\n",
            "There are 50614 examples\n",
            "Total reward = 10.539999999999988 after 100 steps\n",
            "Total reward = 27.064000000000043 after 200 steps\n",
            "Total reward = 41.603999999999914 after 300 steps\n",
            "There are 50968 examples\n",
            "Total reward = 14.684000000000026 after 100 steps\n",
            "Total reward = 27.206000000000095 after 200 steps\n",
            "Total reward = 38.13999999999996 after 300 steps\n",
            "Total reward = 49.72999999999979 after 400 steps\n",
            "Total reward = 64.65799999999953 after 500 steps\n",
            "Total reward = 75.65799999999925 after 600 steps\n",
            "There are 51596 examples\n",
            "Total reward = 16.79400000000002 after 100 steps\n",
            "Total reward = 32.70000000000008 after 200 steps\n",
            "Total reward = 45.62399999999981 after 300 steps\n",
            "There are 51948 examples\n",
            "Total reward = 14.71000000000003 after 100 steps\n",
            "Total reward = 28.442000000000096 after 200 steps\n",
            "Total reward = 42.1399999999999 after 300 steps\n",
            "Total reward = 55.05399999999964 after 400 steps\n",
            "There are 52389 examples\n",
            "Total reward = 14.844000000000017 after 100 steps\n",
            "Total reward = 27.45400000000007 after 200 steps\n",
            "Total reward = 41.291999999999916 after 300 steps\n",
            "There are 52712 examples\n",
            "Total reward = 14.828000000000026 after 100 steps\n",
            "There are 52872 examples\n",
            "Total reward = 12.838000000000017 after 100 steps\n",
            "There are 52991 examples\n",
            "Total reward = 14.666000000000023 after 100 steps\n",
            "Total reward = 28.422000000000075 after 200 steps\n",
            "There are 53215 examples\n",
            "There are 53288 examples\n",
            "Total reward = 13.786000000000017 after 100 steps\n",
            "Total reward = 25.482000000000077 after 200 steps\n",
            "Total reward = 39.381999999999906 after 300 steps\n",
            "There are 53593 examples\n",
            "Total reward = 15.856000000000025 after 100 steps\n",
            "Total reward = 29.50200000000008 after 200 steps\n",
            "There are 53836 examples\n",
            "Total reward = 12.764000000000015 after 100 steps\n",
            "Total reward = 24.492000000000058 after 200 steps\n",
            "There are 54067 examples\n",
            "Total reward = 14.68400000000003 after 100 steps\n",
            "There are 54249 examples\n",
            "Total reward = 14.834000000000028 after 100 steps\n",
            "There are 54349 examples\n",
            "Total reward = 14.474000000000007 after 100 steps\n",
            "There are 54459 examples\n",
            "Total reward = 17.26200000000002 after 100 steps\n",
            "There are 54573 examples\n",
            "Total reward = 15.790000000000017 after 100 steps\n",
            "There are 54756 examples\n",
            "Total reward = 16.642000000000024 after 100 steps\n",
            "Total reward = 31.006000000000057 after 200 steps\n",
            "There are 54964 examples\n",
            "Total reward = 11.870000000000013 after 100 steps\n",
            "Total reward = 25.63200000000005 after 200 steps\n",
            "Total reward = 37.46999999999995 after 300 steps\n",
            "Total reward = 48.35399999999968 after 400 steps\n",
            "Total reward = 59.29599999999941 after 500 steps\n",
            "Total reward = 68.23999999999916 after 600 steps\n",
            "Total reward = 80.12999999999913 after 700 steps\n",
            "There are 55669 examples\n",
            "Total reward = 12.630000000000017 after 100 steps\n",
            "Total reward = 26.296000000000078 after 200 steps\n",
            "Total reward = 35.2940000000001 after 300 steps\n",
            "Total reward = 46.03399999999986 after 400 steps\n",
            "There are 56124 examples\n",
            "Total reward = 15.758000000000013 after 100 steps\n",
            "Total reward = 32.65400000000004 after 200 steps\n",
            "There are 56396 examples\n",
            "Total reward = 15.732000000000028 after 100 steps\n",
            "There are 56517 examples\n",
            "Total reward = 13.772000000000006 after 100 steps\n",
            "Total reward = 30.364000000000043 after 200 steps\n",
            "There are 56720 examples\n",
            "Total reward = 13.504000000000017 after 100 steps\n",
            "There are 56851 examples\n",
            "Total reward = 14.564000000000014 after 100 steps\n",
            "There are 56974 examples\n",
            "Total reward = 16.71000000000004 after 100 steps\n",
            "There are 57121 examples\n",
            "Total reward = 18.70000000000003 after 100 steps\n",
            "There are 57309 examples\n",
            "Total reward = 13.814000000000018 after 100 steps\n",
            "Total reward = 27.322000000000063 after 200 steps\n",
            "Total reward = 40.659999999999975 after 300 steps\n",
            "There are 57655 examples\n",
            "Total reward = 13.83400000000002 after 100 steps\n",
            "Total reward = 27.324000000000073 after 200 steps\n",
            "There are 57917 examples\n",
            "Total reward = 14.598000000000017 after 100 steps\n",
            "There are 58078 examples\n",
            "Total reward = 13.764000000000014 after 100 steps\n",
            "Total reward = 26.46000000000009 after 200 steps\n",
            "There are 58284 examples\n",
            "Total reward = 14.824000000000023 after 100 steps\n",
            "Total reward = 29.324000000000055 after 200 steps\n",
            "Total reward = 42.063999999999886 after 300 steps\n",
            "Total reward = 57.05399999999961 after 400 steps\n",
            "Total reward = 73.04999999999933 after 500 steps\n",
            "There are 58852 examples\n",
            "Total reward = 14.792000000000023 after 100 steps\n",
            "Total reward = 29.29800000000008 after 200 steps\n",
            "Total reward = 38.98999999999989 after 300 steps\n",
            "There are 59196 examples\n",
            "Total reward = 13.858 after 100 steps\n",
            "Total reward = 29.450000000000045 after 200 steps\n",
            "There are 59436 examples\n",
            "Total reward = 17.62800000000003 after 100 steps\n",
            "Total reward = 31.08000000000009 after 200 steps\n",
            "Total reward = 43.73199999999987 after 300 steps\n",
            "There are 59739 examples\n",
            "Total reward = 15.55000000000002 after 100 steps\n",
            "Total reward = 29.482000000000085 after 200 steps\n",
            "Total reward = 41.39799999999992 after 300 steps\n",
            "There are 60043 examples\n",
            "Total reward = 16.444000000000024 after 100 steps\n",
            "Total reward = 31.128000000000082 after 200 steps\n",
            "There are 60330 examples\n",
            "Total reward = 17.630000000000017 after 100 steps\n",
            "There are 60459 examples\n",
            "Total reward = 16.824000000000016 after 100 steps\n",
            "There are 60586 examples\n",
            "Total reward = 16.398000000000014 after 100 steps\n",
            "There are 60743 examples\n",
            "Total reward = 11.614000000000013 after 100 steps\n",
            "There are 60884 examples\n",
            "Total reward = 14.862000000000018 after 100 steps\n",
            "Total reward = 29.556000000000076 after 200 steps\n",
            "There are 61143 examples\n",
            "Total reward = 14.524000000000019 after 100 steps\n",
            "There are 61298 examples\n",
            "Total reward = 16.59800000000002 after 100 steps\n",
            "Total reward = 32.38800000000008 after 200 steps\n",
            "There are 61557 examples\n",
            "Total reward = 17.63200000000002 after 100 steps\n",
            "Total reward = 29.116000000000074 after 200 steps\n",
            "Total reward = 39.79599999999995 after 300 steps\n",
            "Total reward = 53.76199999999967 after 400 steps\n",
            "There are 62004 examples\n",
            "Total reward = 14.828000000000017 after 100 steps\n",
            "Total reward = 29.112000000000073 after 200 steps\n",
            "Total reward = 39.67399999999993 after 300 steps\n",
            "Total reward = 49.37999999999971 after 400 steps\n",
            "There are 62492 examples\n",
            "Total reward = 15.460000000000024 after 100 steps\n",
            "Total reward = 32.31600000000005 after 200 steps\n",
            "Total reward = 44.1959999999998 after 300 steps\n",
            "There are 62851 examples\n",
            "There are 62924 examples\n",
            "There are 63012 examples\n",
            "Total reward = 16.794000000000036 after 100 steps\n",
            "Total reward = 31.594000000000094 after 200 steps\n",
            "There are 63270 examples\n",
            "Total reward = 14.516000000000009 after 100 steps\n",
            "There are 63390 examples\n",
            "Total reward = 14.868000000000029 after 100 steps\n",
            "Total reward = 27.71200000000009 after 200 steps\n",
            "There are 63627 examples\n",
            "Total reward = 13.538000000000018 after 100 steps\n",
            "There are 63818 examples\n",
            "Total reward = 12.754000000000016 after 100 steps\n",
            "Total reward = 27.53800000000008 after 200 steps\n",
            "There are 64062 examples\n",
            "Total reward = 14.43800000000002 after 100 steps\n",
            "Total reward = 27.332000000000082 after 200 steps\n",
            "Total reward = 40.07199999999994 after 300 steps\n",
            "Total reward = 51.9159999999997 after 400 steps\n",
            "There are 64484 examples\n",
            "Total reward = 14.782000000000028 after 100 steps\n",
            "There are 64628 examples\n",
            "Total reward = 15.866000000000016 after 100 steps\n",
            "Total reward = 30.58200000000008 after 200 steps\n",
            "There are 64856 examples\n",
            "Total reward = 17.512000000000018 after 100 steps\n",
            "There are 64996 examples\n",
            "Total reward = 15.470000000000011 after 100 steps\n",
            "Total reward = 28.18800000000007 after 200 steps\n",
            "Total reward = 41.063999999999844 after 300 steps\n",
            "There are 65380 examples\n",
            "Total reward = 16.92200000000002 after 100 steps\n",
            "Total reward = 30.450000000000085 after 200 steps\n",
            "There are 65619 examples\n",
            "Total reward = 13.466000000000008 after 100 steps\n",
            "There are 65754 examples\n",
            "Total reward = 14.612000000000032 after 100 steps\n",
            "There are 65927 examples\n",
            "Total reward = 17.64000000000003 after 100 steps\n",
            "There are 66125 examples\n",
            "Total reward = 13.818000000000008 after 100 steps\n",
            "Total reward = 30.60600000000007 after 200 steps\n",
            "There are 66352 examples\n",
            "Total reward = 12.684000000000015 after 100 steps\n",
            "Total reward = 28.22800000000008 after 200 steps\n",
            "Total reward = 37.06199999999996 after 300 steps\n",
            "There are 66708 examples\n",
            "Total reward = 17.63000000000003 after 100 steps\n",
            "Total reward = 29.474000000000085 after 200 steps\n",
            "There are 66963 examples\n",
            "Total reward = 16.534000000000017 after 100 steps\n",
            "There are 67126 examples\n",
            "Total reward = 13.944000000000011 after 100 steps\n",
            "Total reward = 25.654000000000067 after 200 steps\n",
            "Total reward = 41.547999999999924 after 300 steps\n",
            "Total reward = 53.539999999999644 after 400 steps\n",
            "There are 67587 examples\n",
            "Total reward = 14.664000000000012 after 100 steps\n",
            "Total reward = 27.290000000000067 after 200 steps\n",
            "Total reward = 37.95999999999991 after 300 steps\n",
            "Total reward = 47.921999999999635 after 400 steps\n",
            "There are 68008 examples\n",
            "Total reward = 14.77600000000002 after 100 steps\n",
            "Total reward = 27.096000000000082 after 200 steps\n",
            "Total reward = 41.74399999999993 after 300 steps\n",
            "Total reward = 56.61199999999969 after 400 steps\n",
            "Total reward = 69.60599999999941 after 500 steps\n",
            "Total reward = 82.60599999999913 after 600 steps\n",
            "There are 68620 examples\n",
            "Total reward = 15.644000000000029 after 100 steps\n",
            "Total reward = 30.15000000000008 after 200 steps\n",
            "There are 68908 examples\n",
            "Total reward = 15.570000000000014 after 100 steps\n",
            "Total reward = 30.396000000000072 after 200 steps\n",
            "Total reward = 42.11399999999987 after 300 steps\n",
            "There are 69286 examples\n",
            "Total reward = 11.348000000000004 after 100 steps\n",
            "Total reward = 28.09200000000006 after 200 steps\n",
            "There are 69511 examples\n",
            "Total reward = 13.520000000000014 after 100 steps\n",
            "Total reward = 29.288000000000082 after 200 steps\n",
            "Total reward = 44.21999999999986 after 300 steps\n",
            "Total reward = 55.1339999999996 after 400 steps\n",
            "Total reward = 66.13199999999932 after 500 steps\n",
            "There are 70024 examples\n",
            "Total reward = 17.744000000000025 after 100 steps\n",
            "Total reward = 35.64600000000002 after 200 steps\n",
            "Total reward = 44.53199999999977 after 300 steps\n",
            "Total reward = 55.26199999999951 after 400 steps\n",
            "There are 70455 examples\n",
            "Total reward = 14.760000000000018 after 100 steps\n",
            "Total reward = 29.236000000000075 after 200 steps\n",
            "Total reward = 43.0919999999999 after 300 steps\n",
            "Total reward = 57.08999999999962 after 400 steps\n",
            "Total reward = 66.05999999999933 after 500 steps\n",
            "There are 70966 examples\n",
            "Total reward = 15.866000000000032 after 100 steps\n",
            "Total reward = 29.8460000000001 after 200 steps\n",
            "There are 71224 examples\n",
            "Total reward = 14.834000000000017 after 100 steps\n",
            "There are 71381 examples\n",
            "Total reward = 15.456000000000028 after 100 steps\n",
            "Total reward = 28.936000000000085 after 200 steps\n",
            "There are 71671 examples\n",
            "Total reward = 14.65800000000002 after 100 steps\n",
            "Total reward = 29.310000000000077 after 200 steps\n",
            "Total reward = 45.12599999999991 after 300 steps\n",
            "There are 71983 examples\n",
            "Total reward = 15.832000000000024 after 100 steps\n",
            "Total reward = 27.612000000000076 after 200 steps\n",
            "There are 72221 examples\n",
            "Total reward = 14.754000000000019 after 100 steps\n",
            "Total reward = 28.360000000000074 after 200 steps\n",
            "There are 72506 examples\n",
            "Total reward = 14.762000000000016 after 100 steps\n",
            "There are 72646 examples\n",
            "Total reward = 16.752000000000024 after 100 steps\n",
            "Total reward = 32.56600000000003 after 200 steps\n",
            "Total reward = 44.49799999999976 after 300 steps\n",
            "Total reward = 57.457999999999494 after 400 steps\n",
            "There are 73059 examples\n",
            "Total reward = 16.932000000000034 after 100 steps\n",
            "Total reward = 30.38000000000008 after 200 steps\n",
            "Total reward = 43.30199999999984 after 300 steps\n",
            "There are 73427 examples\n",
            "Total reward = 15.692000000000018 after 100 steps\n",
            "Total reward = 27.298000000000076 after 200 steps\n",
            "There are 73724 examples\n",
            "Total reward = 13.598000000000024 after 100 steps\n",
            "Total reward = 31.454000000000065 after 200 steps\n",
            "Total reward = 45.38599999999981 after 300 steps\n",
            "There are 74030 examples\n",
            "Total reward = 14.662000000000022 after 100 steps\n",
            "Total reward = 29.508000000000084 after 200 steps\n",
            "Total reward = 48.25599999999986 after 300 steps\n",
            "There are 74333 examples\n",
            "Total reward = 16.720000000000024 after 100 steps\n",
            "Total reward = 30.66200000000009 after 200 steps\n",
            "There are 74595 examples\n",
            "Total reward = 15.66000000000003 after 100 steps\n",
            "Total reward = 28.200000000000085 after 200 steps\n",
            "There are 74883 examples\n",
            "Total reward = 14.908000000000023 after 100 steps\n",
            "There are 75060 examples\n",
            "There are 75154 examples\n",
            "Total reward = 16.83000000000003 after 100 steps\n",
            "Total reward = 29.598000000000088 after 200 steps\n",
            "Total reward = 41.18399999999991 after 300 steps\n",
            "There are 75462 examples\n",
            "Total reward = 13.794000000000016 after 100 steps\n",
            "Total reward = 28.29800000000007 after 200 steps\n",
            "There are 75708 examples\n",
            "Total reward = 13.684000000000022 after 100 steps\n",
            "There are 75850 examples\n",
            "Total reward = 15.83800000000003 after 100 steps\n",
            "There are 76043 examples\n",
            "Total reward = 15.742000000000019 after 100 steps\n",
            "Total reward = 29.30800000000007 after 200 steps\n",
            "Total reward = 37.81 after 300 steps\n",
            "There are 76399 examples\n",
            "Total reward = 16.62400000000003 after 100 steps\n",
            "There are 76583 examples\n",
            "Total reward = 15.49200000000002 after 100 steps\n",
            "Total reward = 28.988000000000067 after 200 steps\n",
            "Total reward = 39.6739999999999 after 300 steps\n",
            "There are 76982 examples\n",
            "Total reward = 16.086000000000006 after 100 steps\n",
            "Total reward = 31.85400000000005 after 200 steps\n",
            "There are 77259 examples\n",
            "There are 77331 examples\n",
            "Total reward = 13.672000000000024 after 100 steps\n",
            "Total reward = 28.478000000000087 after 200 steps\n",
            "There are 77626 examples\n",
            "Total reward = 16.448000000000025 after 100 steps\n",
            "Total reward = 31.288000000000082 after 200 steps\n",
            "Total reward = 43.193999999999804 after 300 steps\n",
            "Total reward = 51.113999999999535 after 400 steps\n",
            "There are 78046 examples\n",
            "Total reward = 13.792000000000018 after 100 steps\n",
            "Total reward = 28.57200000000008 after 200 steps\n",
            "Total reward = 40.113999999999955 after 300 steps\n",
            "Total reward = 54.06599999999971 after 400 steps\n",
            "There are 78506 examples\n",
            "Total reward = 16.648000000000003 after 100 steps\n",
            "Total reward = 31.532000000000068 after 200 steps\n",
            "Total reward = 41.41599999999983 after 300 steps\n",
            "Total reward = 53.36399999999957 after 400 steps\n",
            "There are 78943 examples\n",
            "Total reward = 14.796000000000019 after 100 steps\n",
            "Total reward = 28.364000000000058 after 200 steps\n",
            "Total reward = 40.269999999999904 after 300 steps\n",
            "There are 79312 examples\n",
            "Total reward = 16.64200000000002 after 100 steps\n",
            "Total reward = 29.346000000000057 after 200 steps\n",
            "There are 79594 examples\n",
            "Total reward = 14.700000000000022 after 100 steps\n",
            "Total reward = 26.20600000000006 after 200 steps\n",
            "There are 79815 examples\n",
            "Total reward = 14.860000000000023 after 100 steps\n",
            "Total reward = 27.656000000000084 after 200 steps\n",
            "There are 80086 examples\n",
            "There are 80138 examples\n",
            "Total reward = 14.590000000000012 after 100 steps\n",
            "Total reward = 28.302000000000085 after 200 steps\n",
            "There are 80428 examples\n",
            "Total reward = 14.804000000000023 after 100 steps\n",
            "Total reward = 25.392000000000074 after 200 steps\n",
            "Total reward = 37.26199999999998 after 300 steps\n",
            "Total reward = 49.08999999999971 after 400 steps\n",
            "Total reward = 58.86399999999949 after 500 steps\n",
            "There are 80988 examples\n",
            "Total reward = 14.850000000000028 after 100 steps\n",
            "Total reward = 30.55000000000009 after 200 steps\n",
            "Total reward = 44.515999999999835 after 300 steps\n",
            "Total reward = 54.51199999999955 after 400 steps\n",
            "Total reward = 65.50999999999928 after 500 steps\n",
            "There are 81543 examples\n",
            "Total reward = 14.832000000000027 after 100 steps\n",
            "There are 81662 examples\n",
            "Total reward = 15.89600000000003 after 100 steps\n",
            "Total reward = 28.77400000000009 after 200 steps\n",
            "There are 81928 examples\n",
            "Total reward = 14.624000000000017 after 100 steps\n",
            "There are 82104 examples\n",
            "Total reward = 12.814000000000016 after 100 steps\n",
            "Total reward = 28.752000000000084 after 200 steps\n",
            "Total reward = 39.49199999999993 after 300 steps\n",
            "Total reward = 51.42599999999966 after 400 steps\n",
            "There are 82509 examples\n",
            "Total reward = 16.37400000000002 after 100 steps\n",
            "Total reward = 32.11000000000007 after 200 steps\n",
            "Total reward = 42.80199999999984 after 300 steps\n",
            "There are 82852 examples\n",
            "Total reward = 15.602000000000023 after 100 steps\n",
            "Total reward = 29.362000000000084 after 200 steps\n",
            "Total reward = 40.31799999999988 after 300 steps\n",
            "There are 83182 examples\n",
            "Total reward = 14.402000000000006 after 100 steps\n",
            "Total reward = 30.22200000000007 after 200 steps\n",
            "Total reward = 40.087999999999866 after 300 steps\n",
            "Total reward = 50.95399999999962 after 400 steps\n",
            "There are 83616 examples\n",
            "Total reward = 14.750000000000021 after 100 steps\n",
            "There are 83811 examples\n",
            "Total reward = 16.880000000000024 after 100 steps\n",
            "Total reward = 29.306000000000072 after 200 steps\n",
            "There are 84086 examples\n",
            "There are 84184 examples\n",
            "Total reward = 12.592000000000004 after 100 steps\n",
            "Total reward = 24.25000000000006 after 200 steps\n",
            "There are 84439 examples\n",
            "Total reward = 15.53400000000002 after 100 steps\n",
            "Total reward = 31.216000000000083 after 200 steps\n",
            "There are 84673 examples\n",
            "Total reward = 14.754000000000028 after 100 steps\n",
            "Total reward = 29.19600000000007 after 200 steps\n",
            "Total reward = 43.84399999999988 after 300 steps\n",
            "Total reward = 57.48999999999966 after 400 steps\n",
            "Total reward = 68.47599999999939 after 500 steps\n",
            "There are 85194 examples\n",
            "Total reward = 15.348000000000027 after 100 steps\n",
            "Total reward = 32.26800000000007 after 200 steps\n",
            "Total reward = 43.95599999999982 after 300 steps\n",
            "There are 85586 examples\n",
            "Total reward = 12.682000000000025 after 100 steps\n",
            "Total reward = 28.44600000000008 after 200 steps\n",
            "Total reward = 42.37599999999991 after 300 steps\n",
            "There are 85978 examples\n",
            "Total reward = 14.506000000000029 after 100 steps\n",
            "There are 86130 examples\n",
            "Total reward = 17.688000000000027 after 100 steps\n",
            "There are 86265 examples\n",
            "Total reward = 15.60800000000002 after 100 steps\n",
            "There are 86454 examples\n",
            "Total reward = 20.910000000000032 after 100 steps\n",
            "Total reward = 36.71400000000001 after 200 steps\n",
            "There are 86664 examples\n",
            "Total reward = 15.800000000000027 after 100 steps\n",
            "Total reward = 28.328000000000078 after 200 steps\n",
            "Total reward = 41.031999999999904 after 300 steps\n",
            "There are 86993 examples\n",
            "Total reward = 15.694000000000022 after 100 steps\n",
            "There are 87172 examples\n",
            "Total reward = 17.652000000000015 after 100 steps\n",
            "Total reward = 31.26600000000008 after 200 steps\n",
            "Total reward = 47.11199999999983 after 300 steps\n",
            "Total reward = 57.083999999999584 after 400 steps\n",
            "Total reward = 70.0839999999993 after 500 steps\n",
            "There are 87691 examples\n",
            "Total reward = 16.476000000000024 after 100 steps\n",
            "Total reward = 30.244000000000096 after 200 steps\n",
            "Total reward = 40.163999999999874 after 300 steps\n",
            "Total reward = 57.1599999999996 after 400 steps\n",
            "There are 88092 examples\n",
            "Total reward = 16.344000000000023 after 100 steps\n",
            "There are 88219 examples\n",
            "Total reward = 17.61000000000002 after 100 steps\n",
            "There are 88388 examples\n",
            "Total reward = 16.16200000000001 after 100 steps\n",
            "There are 88553 examples\n",
            "Total reward = 17.62800000000002 after 100 steps\n",
            "Total reward = 32.46600000000009 after 200 steps\n",
            "Total reward = 42.407999999999824 after 300 steps\n",
            "There are 88902 examples\n",
            "Total reward = 13.786000000000005 after 100 steps\n",
            "Total reward = 26.528000000000063 after 200 steps\n",
            "There are 89162 examples\n",
            "Total reward = 13.900000000000015 after 100 steps\n",
            "Total reward = 24.80400000000008 after 200 steps\n",
            "Total reward = 38.516000000000055 after 300 steps\n",
            "There are 89475 examples\n",
            "Total reward = 15.736000000000024 after 100 steps\n",
            "Total reward = 27.30800000000009 after 200 steps\n",
            "Total reward = 41.993999999999964 after 300 steps\n",
            "Total reward = 53.903999999999705 after 400 steps\n",
            "There are 89881 examples\n",
            "Total reward = 14.85600000000002 after 100 steps\n",
            "Total reward = 29.672000000000075 after 200 steps\n",
            "There are 90091 examples\n",
            "There are 90184 examples\n",
            "Total reward = 15.894000000000034 after 100 steps\n",
            "Total reward = 28.59600000000009 after 200 steps\n",
            "There are 90394 examples\n",
            "Total reward = 14.57400000000002 after 100 steps\n",
            "Total reward = 28.04200000000006 after 200 steps\n",
            "There are 90599 examples\n",
            "Total reward = 13.388000000000027 after 100 steps\n",
            "Total reward = 25.1940000000001 after 200 steps\n",
            "Total reward = 40.008 after 300 steps\n",
            "There are 90939 examples\n",
            "Total reward = 15.592000000000024 after 100 steps\n",
            "Total reward = 27.15200000000008 after 200 steps\n",
            "There are 91229 examples\n",
            "Total reward = 16.748000000000015 after 100 steps\n",
            "There are 91377 examples\n",
            "Total reward = 16.60000000000003 after 100 steps\n",
            "There are 91541 examples\n",
            "Total reward = 14.584000000000026 after 100 steps\n",
            "There are 91666 examples\n",
            "Total reward = 13.858000000000015 after 100 steps\n",
            "Total reward = 28.79800000000006 after 200 steps\n",
            "Total reward = 41.71599999999985 after 300 steps\n",
            "There are 91994 examples\n",
            "Total reward = 12.762000000000016 after 100 steps\n",
            "Total reward = 27.666000000000082 after 200 steps\n",
            "Total reward = 41.611999999999895 after 300 steps\n",
            "There are 92391 examples\n",
            "Total reward = 12.846000000000018 after 100 steps\n",
            "Total reward = 27.494000000000067 after 200 steps\n",
            "There are 92653 examples\n",
            "Total reward = 13.640000000000018 after 100 steps\n",
            "There are 92778 examples\n",
            "Total reward = 15.856000000000025 after 100 steps\n",
            "Total reward = 28.7040000000001 after 200 steps\n",
            "Total reward = 37.35199999999997 after 300 steps\n",
            "Total reward = 49.3119999999997 after 400 steps\n",
            "There are 93233 examples\n",
            "Total reward = 14.706000000000028 after 100 steps\n",
            "Total reward = 30.422000000000097 after 200 steps\n",
            "There are 93494 examples\n",
            "Total reward = 14.750000000000002 after 100 steps\n",
            "Total reward = 27.96600000000004 after 200 steps\n",
            "There are 93740 examples\n",
            "Total reward = 15.776000000000037 after 100 steps\n",
            "Total reward = 25.648000000000103 after 200 steps\n",
            "Total reward = 35.202000000000055 after 300 steps\n",
            "Total reward = 48.99199999999981 after 400 steps\n",
            "There are 94205 examples\n",
            "Total reward = 14.45400000000002 after 100 steps\n",
            "Total reward = 27.15800000000008 after 200 steps\n",
            "There are 94447 examples\n",
            "Total reward = 16.81000000000003 after 100 steps\n",
            "Total reward = 28.37000000000005 after 200 steps\n",
            "Total reward = 45.14399999999984 after 300 steps\n",
            "There are 94797 examples\n",
            "Total reward = 14.590000000000012 after 100 steps\n",
            "Total reward = 31.202000000000062 after 200 steps\n",
            "There are 95045 examples\n",
            "Total reward = 13.69200000000002 after 100 steps\n",
            "There are 95187 examples\n",
            "Total reward = 13.706000000000012 after 100 steps\n",
            "Total reward = 28.05200000000006 after 200 steps\n",
            "There are 95458 examples\n",
            "Total reward = 13.472000000000026 after 100 steps\n",
            "Total reward = 27.41600000000009 after 200 steps\n",
            "Total reward = 40.25600000000002 after 300 steps\n",
            "There are 95768 examples\n",
            "Total reward = 15.37000000000002 after 100 steps\n",
            "Total reward = 30.914000000000065 after 200 steps\n",
            "Total reward = 42.76399999999983 after 300 steps\n",
            "Total reward = 51.74399999999956 after 400 steps\n",
            "There are 96250 examples\n",
            "Total reward = 14.652000000000028 after 100 steps\n",
            "Total reward = 28.26800000000009 after 200 steps\n",
            "Total reward = 42.063999999999936 after 300 steps\n",
            "Total reward = 55.00399999999967 after 400 steps\n",
            "Total reward = 65.91799999999941 after 500 steps\n",
            "There are 96837 examples\n",
            "Total reward = 14.830000000000028 after 100 steps\n",
            "There are 96977 examples\n",
            "Total reward = 15.666000000000022 after 100 steps\n",
            "Total reward = 28.17800000000008 after 200 steps\n",
            "Total reward = 42.03199999999994 after 300 steps\n",
            "There are 97341 examples\n",
            "Total reward = 12.938000000000017 after 100 steps\n",
            "There are 97488 examples\n",
            "Total reward = 14.704000000000017 after 100 steps\n",
            "Total reward = 27.172000000000057 after 200 steps\n",
            "There are 97742 examples\n",
            "Total reward = 14.65000000000001 after 100 steps\n",
            "Total reward = 30.324000000000066 after 200 steps\n",
            "Total reward = 42.15999999999984 after 300 steps\n",
            "Total reward = 56.089999999999584 after 400 steps\n",
            "There are 98214 examples\n",
            "Total reward = 13.92200000000002 after 100 steps\n",
            "Total reward = 27.440000000000083 after 200 steps\n",
            "Total reward = 39.312 after 300 steps\n",
            "There are 98552 examples\n",
            "Total reward = 15.76600000000002 after 100 steps\n",
            "Total reward = 29.360000000000092 after 200 steps\n",
            "There are 98848 examples\n",
            "There are 98944 examples\n",
            "Total reward = 13.51400000000001 after 100 steps\n",
            "Total reward = 30.356000000000073 after 200 steps\n",
            "Total reward = 40.261999999999844 after 300 steps\n",
            "There are 99310 examples\n",
            "Total reward = 14.744000000000016 after 100 steps\n",
            "Total reward = 28.42000000000007 after 200 steps\n",
            "Total reward = 40.25199999999991 after 300 steps\n",
            "Total reward = 51.20199999999963 after 400 steps\n",
            "There are 99710 examples\n",
            "Total reward = 15.85800000000002 after 100 steps\n",
            "Total reward = 29.472000000000087 after 200 steps\n",
            "There are 99913 examples\n",
            "Total reward = 15.652000000000026 after 100 steps\n",
            "There are 100102 examples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent = DqnAgent(game)\n",
        "agent.train(\n",
        "    10,\n",
        "    min_epsilon=0.1,\n",
        "    max_epsilon=1,\n",
        "    decay=0.5,  # TODO: try linear decay\n",
        "    learning_rate=0.001,\n",
        "    epochs=200,\n",
        "    min_steps_to_update_target_model=20,\n",
        "    discount_factor=0.6,\n",
        "    batch_size=512,\n",
        "    initial_examples=initial_examples,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        },
        "id": "RSXbdOuDpiAa",
        "outputId": "4f7dbc01-3654-4e86-c966-792193ace374"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 [==============================] - 1s 72ms/step\n",
            "16/16 [==============================] - 1s 64ms/step\n",
            "Epoch 1/10\n",
            "8/8 [==============================] - 3s 348ms/step - loss: 1.9611\n",
            "Epoch 2/10\n",
            "8/8 [==============================] - 3s 353ms/step - loss: 1.2778\n",
            "Epoch 3/10\n",
            "8/8 [==============================] - 3s 351ms/step - loss: 1.1372\n",
            "Epoch 4/10\n",
            "8/8 [==============================] - 4s 515ms/step - loss: 1.0280\n",
            "Epoch 5/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-81-788001c7742e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDqnAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m agent.train(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmin_epsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmax_epsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-78-5d8d78fbde81>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, episodes, min_epsilon, max_epsilon, decay, learning_rate, discount_factor, epochs, initial_examples, batch_size, min_steps_to_update_target_model)\u001b[0m\n\u001b[1;32m    137\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplay_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mstep_counter\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscount_factor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m                 \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mtotal_reward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-78-5d8d78fbde81>\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self, done, discount_factor, batch_size, epochs)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mcurrent_qs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_qs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_future_qs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         self.model.fit(\n\u001b[0m\u001b[1;32m    106\u001b[0m             \u001b[0mcurrent_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_qs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1683\u001b[0m                         ):\n\u001b[1;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_functions_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_function_call\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"eager\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m     \u001b[0;31m# Only count the statistics the first time, before initialization took\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m   1282\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1283\u001b[0m                 \u001b[0;34m\"\"\"Runs a training execution with a single step.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1284\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mstep_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1286\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mstep_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m   1266\u001b[0m                 )\n\u001b[1;32m   1267\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1268\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1269\u001b[0m             outputs = reduce_per_replica(\n\u001b[1;32m   1270\u001b[0m                 \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1314\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m   1315\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 1316\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2893\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2894\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2895\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2897\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3694\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3695\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3696\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3698\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    593\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUNSPECIFIED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1248\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1249\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1250\u001b[0m                 \u001b[0;31m# Ensure counter is updated only if `train_step` succeeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1251\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1052\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_target_and_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0;31m# Run backwards pass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/optimizers/optimizer.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self, loss, var_list, tape)\u001b[0m\n\u001b[1;32m    540\u001b[0m           \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m         \"\"\"\n\u001b[0;32m--> 542\u001b[0;31m         \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/optimizers/optimizer.py\u001b[0m in \u001b[0;36mcompute_gradients\u001b[0;34m(self, loss, var_list, tape)\u001b[0m\n\u001b[1;32m    273\u001b[0m                     \u001b[0mvar_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1061\u001b[0m                           for x in output_gradients]\n\u001b[1;32m   1062\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0m\u001b[1;32m   1064\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m         \u001b[0mflat_targets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \"Unknown value for unconnected_gradients: %r\" % unconnected_gradients)\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m   return pywrap_tfe.TFE_Py_TapeGradient(\n\u001b[0m\u001b[1;32m     68\u001b[0m       \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    144\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/nn_grad.py\u001b[0m in \u001b[0;36m_Conv2DGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    590\u001b[0m           \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m           data_format=data_format),\n\u001b[0;32m--> 592\u001b[0;31m       gen_nn_ops.conv2d_backprop_filter(\n\u001b[0m\u001b[1;32m    593\u001b[0m           \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m           \u001b[0mshape_1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d_backprop_filter\u001b[0;34m(input, filter_sizes, out_backprop, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1253\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   1256\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Conv2DBackpropFilter\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_backprop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1257\u001b[0m         \u001b[0;34m\"strides\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"use_cudnn_on_gpu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"padding\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent.plot_rewards()"
      ],
      "metadata": {
        "id": "GnrJkEdjr41c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent._play_game()"
      ],
      "metadata": {
        "id": "62UHskES7q1t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}